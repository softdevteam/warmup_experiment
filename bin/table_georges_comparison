#!/usr/bin/env python2.7

"""
Create a LaTeX summary comparing annotated Krun results to those reported by
the method described in Georges et. al. (2007).
"""

import argparse
import numpy
import os
import os.path
import sys

sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from warmup.krun_results import parse_krun_file_with_changepoints
from warmup.latex import preamble, end_document, end_table
from warmup.latex import machine_name_to_macro, STYLE_SYMBOLS


_TITLE = 'Comparison with Georges et. al. (2007)'
_START_TABLE = lambda format_, headings: """
{
\\begin{tabular}{%s}
\\toprule
%s \\\\
\\midrule
""" % (format_, headings)

_NUMBERS = {0:'zero', 1:'one', 2:'two', 3:'three', 4:'four', 5:'five',
            6:'six', 7:'seven', 8:'eight', 9:'nine'}


def _start_table(format_, headings):
    """Unlike the start_table() function in warmup.latex, this one does not
    contain any code to configure sparklines.
    """

    return _START_TABLE(format_, headings)


def _cov(data):
    """Computes the coefficient of variation of data."""

    return numpy.std(data) / numpy.mean(data)


def compute_comparison(in_files, threshold):
    """For each classification type, find the number of process executions that
    Georges et. al. (2007) would have classified as having a steady state.
    """

    classifier, data_dictionaries = parse_krun_file_with_changepoints(in_files)
    steady = classifier['steady']  # Min iterations expected in steady state.
    counts = dict()
    for machine in data_dictionaries:
        counts[machine] = {'warmup': 0, 'slowdown': 0, 'flat': 0,
                            'no steady state': 0, 'total warmup': 0,
                            'total flat': 0, 'total slowdown': 0,
                            'total no steady state': 0}
        keys = sorted(data_dictionaries[machine]['wallclock_times'].keys())
        for key in sorted(keys):
            wallclock_times = data_dictionaries[machine]['wallclock_times'][key]
            if len(wallclock_times) == 0:
                print('WARNING: Skipping: %s from %s (no executions)' %
                       (key, machine))
            elif len(wallclock_times[0]) == 0:
                print('WARNING: Skipping: %s from %s (benchmark crashed)' %
                      (key, machine))
            else:
                bench, vm, variant = key.split(':')
                n_pexecs = len(data_dictionaries[machine]['wallclock_times'][key])
                # In the Georges et al. (2007) paper, measurements are defined
                # as x_i,j where i is the ith invocation of the VM, and j is
                # a benchmark iteration. In this code pexec is "i", and iteration
                # "j". The "k" iterations that we might to retain (i.e. the
                # minimum length of a steady state) is called steady.
                for pexec in xrange(n_pexecs):
                    classification = data_dictionaries[machine]['classifications'][key][pexec]
                    counts[machine]['total ' + classification] += 1
                    iter_length = len(data_dictionaries[machine]['wallclock_times'][key][pexec])
                    for iteration in xrange(steady, iter_length):
                        start = iteration - steady
                        end = iteration + 1
                        this_cov = _cov(data_dictionaries[machine]['wallclock_times'][key][pexec][start:end])
                        if this_cov < threshold:
                            counts[machine][classification] += 1
                            break
    return counts


def write_table(counts, tex_filename, with_preamble=False):
    """Write out LaTeX table."""

    print('Writing data to: %s.' % options.latex_file)
    machines = counts.keys()
    with open(tex_filename, 'w') as fp:
        if with_preamble:
            fp.write(preamble(_TITLE))
            fp.write('\\begin{table*}[t]\n')
            fp.write('\\centering\n')
        table_format = 'l' + ('r' * len(machines))
        table_headings1 = '&'.join(
            ['\multicolumn{1}{c}{\multirow{2}{*}{Classification}}'] +
            ['\multicolumn{%s}{c}{Machine}' % len(machines)])
        table_headings2 = '&'.join(
            [''] + ['\\multicolumn{1}{c}{\\footnotesize %s}' %
                      machine_name_to_macro(name) for name in sorted(machines)])
        table_headings = '\\\\'.join([table_headings1, table_headings2])
        fp.write(_start_table(table_format, table_headings))
        for style in ('flat', 'warmup', 'slowdown', 'no steady state'):
            row = [STYLE_SYMBOLS[style]] + \
                      ['%.2f\\%%' % (float(counts[machine][style]) /
                                     float(counts[machine]['total ' + style]) * 100.0)
                       for machine in sorted(machines)]
            fp.write('%s\\\\ \n' % '&'.join(row))
        fp.write(end_table())
        if with_preamble:
            fp.write('\\end{table*}\n')
            fp.write(end_document())


def _reformat(word):
    """Reformat word as a LaTeX macro name.
    Removes spaces and underscores. Translates numbers to words. Lower cases.
    """

    for number in _NUMBERS:
        word = word.replace(str(number), _NUMBERS[number])
    word = str(word).translate(None, ' _')
    return word.lower()


def write_macros(counts, tex_filename):
    """Write out macros that summarise the information in the table."""

    # Sum data over all machines.
    totals = {'warmup': 0, 'slowdown': 0, 'flat': 0, 'no steady state': 0,
              'total warmup': 0, 'total flat': 0, 'total slowdown': 0,
              'total no steady state': 0}
    for machine in counts:
        for category in ('flat', 'warmup', 'slowdown', 'no steady state'):
            totals[category] += counts[machine][category]
            totals['total ' + category] += counts[machine]['total ' + category]
    print('Writing data to %s.' % tex_filename)
    with open(tex_filename, 'w') as fd:
        fd.write('%%%\n')
        fd.write('%%% Number of benchmarks on that Georges et al. found to reach a state state.\n')
        fd.write('%%%\n')
        for machine in counts:
            mc_name = _reformat(machine)
            for category in ('flat', 'warmup', 'slowdown', 'no steady state'):
                fd.write('\\newcommand{\\%s}{%d}\n' %
                         (_reformat('georges' + mc_name + category), counts[machine][category]))
        fd.write('%%%\n')
        fd.write('%%% Percentage of benchmarks on that Georges et al. found to reach a state state.\n')
        fd.write('%%%\n')
        for machine in counts:
            mc_name = _reformat(machine)
            for category in ('flat', 'warmup', 'slowdown', 'no steady state'):
                fd.write('\\newcommand{\\%s}{%.1f}\n' %
                         (_reformat('georges' + mc_name + category + 'percent'),
                          float(counts[machine][category]) / float(counts[machine]['total ' + category]) * 100.0))
        fd.write('%%%\n')
        fd.write('%%% Percentage of benchmarks over all machines that Georges et al. found to reach a state state.\n')
        fd.write('%%%\n')
        for category in ('flat', 'warmup', 'slowdown', 'no steady state'):
            fd.write('\\newcommand{\\%s}{%.1f}\n' %
                     (_reformat('georges' + category + 'percent'),
                      float(totals[category]) / float(totals['total ' + category]) * 100.0))


def create_cli_parser():
    """Create a parser to deal with command line switches."""

    description = ('Given a number of annotated Krun results files, for each '
                   'classification type, find the number of process executions '
                   'that Georges et. al. (2007) would have classified as '
                   'having a steady state.')
    parser = argparse.ArgumentParser(description,
                                     formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument('json_files', nargs='+', action='append', default=[],
                        type=str, help='One or more JSON result files.')
    parser.add_argument('--threshold', '-t', dest='threshold', action='store',
                        type=float, default=0.01, help='CoV threshold.')
    parser.add_argument('--outfile', '-o', action='store', dest='latex_file',
                        type=str, help='Name of the LaTeX file to write to.',
                        required=True)
    parser.add_argument('--with-preamble', action='store_true',
                        dest='with_preamble', default=False,
                        help='Write out a whole LaTeX article (not just the table).')
    return parser


if __name__ == '__main__':
    parser = create_cli_parser()
    options = parser.parse_args()
    base_filename, extention = os.path.splitext(options.latex_file)
    print('Using CoV threshold %.3f.' % options.threshold)
    counts = compute_comparison(options.json_files[0], options.threshold)
    write_table(counts, options.latex_file, options.with_preamble)
    write_macros(counts, base_filename + '_macros' + extention)
