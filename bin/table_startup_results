#!/usr/bin/env python2.7

"""Create a LaTeX summary of a Krun results file from the startup experiment."""

import argparse
import os
import os.path
import sys

sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from warmup.krun_results import read_krun_results_file
from warmup.latex import preamble, end_document, end_table, escape
from warmup.latex import format_median_error, section, start_table
from warmup.statistics import bootstrap_confidence_interval

TITLE = 'Startup Experiment Results'


def main(data_dcts, latex_file, with_preamble):
    # machine -> vm -> times
    summary_data = {machine: {} for machine in data_dcts.keys()}
    all_vms = set()
    for machine in data_dcts:
        keys = sorted(data_dcts[machine]['wallclock_times'].keys())
        for key in keys:
            wallclock_times = data_dcts[machine]['wallclock_times'][key]
            if len(wallclock_times) == 0:
                print ('WARNING: Skipping: %s from %s (no executions)' %
                       (key, machine))
            elif len(wallclock_times[0]) == 0:
                print('WARNING: Skipping: %s from %s (benchmark crashed)' %
                      (key, machine))
            else:
                # Scaffold summary dictionary.
                vm = key.split(':')[1]
                all_vms |= set([vm])
                if vm not in summary_data[machine]:
                    summary_data[machine][vm] = list()
                # Add data from this key to the summary data.
                startup_times = list()
                for result in wallclock_times:
                    startup_times.append(result[1] - result[0])
                # Average startup times for this process exec.
                summary_data[machine][vm] = startup_times
    # Average the summary data.
    # vm -> machine -> summary
    summary = {vm: {} for vm in all_vms}
    machines = list()
    for machine in summary_data:
        machines.append(machine)
        for vm in all_vms:
            try:
                data = summary_data[machine][vm]
            except KeyError:
                summary[vm][machine] = ''
            else:
                median, error = bootstrap_confidence_interval(
                    data, confidence=0.99)
                sys.stdout.write('.')
                sys.stdout.flush()
                summary[vm][machine] = format_median_error(median, error)

    # Write out results.
    write_results_as_latex(summary, sorted(machines), latex_file, with_preamble)
    return


def write_results_as_latex(summary, machines, tex_filename, with_preamble):
    """Write a results file."""

    print('Writing data to %s.' % tex_filename)
    with open(tex_filename, 'w') as fp:
        sections = (('Startup-times', summary)),
        if with_preamble:
            fp.write(preamble(TITLE))
            fp.write('\\begin{table*}[t]\n')
            fp.write('\\centering\n')
        for section_heading, summary in sections:
            if with_preamble:
                fp.write(section(section_heading))
            table_format = 'l' + ('r' * len(machines))
            table_headings1 = '&'.join(
                ['\multicolumn{1}{c}{\multirow{2}{*}{VM}}'] +
                ['\multicolumn{%s}{c}{Machine}' % len(machines)])
            table_headings2 = '&'.join(
                [''] + ['\\multicolumn{1}{c}{\\footnotesize %s}' %
                          x for x in  machines])
            table_headings = '\\\\'.join([table_headings1, table_headings2])
            fp.write(start_table(table_format, table_headings))
            for vm in sorted(summary.keys()):
                row = [escape(vm)] + \
                    [summary[vm][machine] for machine in machines]
                fp.write('%s\\\\ \n' % '&'.join(row))
            fp.write(end_table())
        if with_preamble:
            fp.write('\\end{table*}\n')
            fp.write(end_document())
    return


def get_data_dictionaries(json_files):
    """Read a list of BZipped JSON files and return their contents as a
    dictionaries of machine name -> JSON values.
    """

    data_dictionary = dict()
    for filename in json_files:
        assert os.path.exists(filename), 'File %s does not exist.' % filename
        print('Loading: %s' % filename)
        data = read_krun_results_file(filename)
        machine_name = data['audit']['uname'].split(' ')[1]
        if '.' in machine_name:  # Remove domain, if there is one.
            machine_name = machine_name.split('.')[0]
        data_dictionary[machine_name] = data
    return data_dictionary


def create_cli_parser():
    """Create a parser to deal with command line switches."""

    script = os.path.basename(__file__)
    description = (('Summarise information from a startup experiment.\n' +
                    'See startup.krun for details.' +
                    '\n\nExample usage:\n\n' +
                    '\t$ python %s -o startup.tex results.json.bz2') % script)
    parser = argparse.ArgumentParser(description=description,
                                     formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument('json_files', action='append', nargs='+', default=[],
                        type=str,
                        help='One or more Krun JSON results files.')
    parser.add_argument('--outfile', '-o', action='store', dest='latex_file',
                        type=str, help='Name of the LaTeX file to write to.',
                        required=True)
    parser.add_argument('--with-preamble', action='store_true',
                        dest='with_preamble', default=False,
                        help='Write out a whole LaTeX article (not just the table).')
    return parser


if __name__ == '__main__':
    parser = create_cli_parser()
    options = parser.parse_args()
    data_dcts = get_data_dictionaries(options.json_files[0])
    if options.with_preamble:
        print 'Writing out full document, with preamble.'
    main(data_dcts, options.latex_file, options.with_preamble)
